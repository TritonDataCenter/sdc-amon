# higher-level prios

- design use cases, assign a use case driver for each prio
- sysevent-based events: use case #2, machine-running-state probe type
- agent in all zones
- MON-120: authorizeDelete finish (should merge with authorizePut logic)
- finish CRUD on UFDS objects
- sdc-healthcheck
- notification formatting: templating? Show open/closed state in notifications.
  Design section on what info should be included in notification.
- MON-113: suppression support (alarms, monitors, everything) -> maintenance windows
- upgrade plan: What if UFDS schema needs to change? How do we rev the Master
  with older agents in the wild. Upgrading Agent versions? What about
  an old amon-agent? old amon-relay?
- cloudapi
- portal (c.f. http://circonus.com/resources/videos#play-video-check-creation)
- adminui
- load testing (hook into mock cloud for this?). Estimate of design-limit on
  number of probes/notifications/events
- HA


# todo (in no particular order)

- dogfood:
    - devs using in kvm test machines
    - devs using in COAL
    - trevor using it in BH-1. For what exactly?
    - monitoring jenkins builds? or space usage in jenkins?
    - space usage on stuff
    - is DSAPI up?
    - is mo.jo up?
    - others? email around
- update to latest ldapjs for #49 and #50 fixes (already done I think)
- update to restify 1.4.1 when that is released (there is a ticket for this)
- update to and use npm shrinkwrap
- removing old alarms after a week
- err cleanup (MON-108)
- Relay needs to have guards for run away agents. One case is an infinite
  loop: a probe watching for "ERROR" in amon logs, where sending the
  event results in an "ERROR". Handle this with relay per-agent throttling
  (can't use restify built-in throttling for this). If over limit, then
  an alarm is created for the monitor owner and the relay ignores or
  closes that zone server/socket.
- Consider adding run-time as attribute on probe events, i.e. how long it
  took the probe to run. Also, send a warning config alarm to a monitor owner
  if a probe is taking too long to run, e.g. a pathological regex. A *really*
  pathological regex (or mdb command) could hang and would need process
  mgmt to deal with. How to break out of this??? A separate process everytime
  is a pain.
- clear event scenario: A monitor with 'machine-up' probes on two zones.
  Both go down. One comes back up. That alarm should not clear, **but it
  does currently**.
- node-retry in PutEvents in RelayClient.
- 'sdc-amon /pub/hamish/monitors/whistle -X DELETE' fails
    ERROR: Error deleting 'amonmonitor=whistle, uuid=7b23ae63-37c9-420e-bb88-8d4bf5e30455, ou=customers, o=smartdc' from UFDS: NotAllowedOnNonLeafError:...
- What if a whole CN goes down? Could have heartbeats from the relays. Then
  have a probetype that fires for "missing" data. I.e. missed a heartbeat
  from the relay. Should this "fire on missing data" be a generic probe
  config thing? Probably.
  See <http://circonus.com/resources/videos#play-video-rule-notifications>
  for generic probe (aka rule) facilities: on match, invert match, on
  value change, on absence.
- <probe>.idObject details on probe events from agent is *wrong*. Insecure.
  The userUuid value must come from relay (and should be the zone owner-uuid
  cfg var). Relay should probably also add the "zone" from which the event
  came? Relay should also validate that given event is for a probe that
  *exists* for that zone, if not then drop it.
- consistent `new restify.FooError(...)` usage and document this
- send an op notification if Redis is down when attempting to process an event
- relay: improve this log line to know which zone/zsock this request came
  from. Perhaps the "unknown" could be the zone name. Also perhaps "anonymous"
  could be the owner uuid (only if no cost to that).
    unknown - anonymous [23/11/2011:21:38:26 GMT] "HEAD /agentprobes HTTP/1.1" 200 0 1
- disallow '/' in name fields (so can use that as sep char for a string id).
  If this isn't acceptable then update id'ification in agent.
  Perhaps ':' would be preferable for id'ification? Meh.
- name fields in Master API: percent escaping
  Also consider adding a "slug" field to Monitor and Probe. This is used as
  the 'id'. Guarantee uniqueness, export method (and library?) for calculating
  the slug. Still allow addressing by name? But perhaps as a query param?
  Think about it. The downside of "whatever goes" name as the only id is:
  inelegant alarm naming (use " 1" or "-1" suffix), potential for edge
  case errors up the stack (portal, cloudapi, adminui) all would have to
  get all the edge cases correct including unicode, PITA for using the API
  on the CLI (hand quoting URL parts), inelegant URLs in the portals
- walk through a server boot (and boot of all its zones): does Amon eventing
  go crazy?
- http://circonus.com/resources/videos#play-video-rule-notifications for
  probe facilities.
- probe types to consider: https://support.cloudkick.com/Category:Checks


# someday/maybe

- more notification types: (see http://circonus.com/why-us/features/notifications)
    AOL and XMPP (Jabber, Google Talk, etc.) Instant Messages
    Twitter (direct messages from @circonusops)
    SMS
    PagerDuty
- saving the alarm events in redis? Are those needed for anything? Not
  bothering until we have UI that would use this.
- endpoint to test sending to a contact "POST /pub/:uuid/testnotify"
- "sdc-amon /pub/trent.mick" messes up on '.' in username -> restify upgrade
  Check for this being fixed with restify 1.x
- amon-relay and amon-agent: move node to build/node (a la portal and others)
- [Trent] master/config.json.in and use that in usb-headnode/zones/amon/setup
- from master/lib/probes.js:
    //XXX validate the type is an existing probe type
    //XXX validate data for that probe type
- [Trent] :login -> :uuid
- Amon test cases for alarming
- docs: move contact URN spec from master/lib/contact.js to the docs
- Idea: have amon-master create event/alarm to operator if it cannot
  connect/work with UFDS.
- look at New Relic: http://newrelic.com/
- test Amon on CN
- throttling on MonitorFakeFault
- [Trent] test suite for relay and agent
- 'ping-agent' probe type. Basically this is a test that the amon-relay <->
  amon-agent socket is working and that the agent is responding.
- from workflow/mapi talk: Amon should have the monitor skel for provisioning
  workflow a la FWAPI (but still use normal Amon comm channel). Spec that.
- check interval: cloudkick checks run every 2.5 minutes.
- use case: modcloth request to have alerts when in CPU bursting range, i.e.
  they are hitting OS caps. In Modcloth's case, they were hitting caps and
  didn't know it.
- amon-relay just fails mostly silently if given agents-probes-dir doesn't exist:
      [15:40:37 trentm@banana:~/joy/amon/relay (ufds)]
      $ ../deps/node-install/bin/node main.js -v -d -D tmp/db -m http://127.0.0.1:8080 -s 8081 -p 90
      2011-11-10 23:40:43Z DEBUG: Checking master for new agent probes.
      2011-11-10 23:40:43Z DEBUG: Starting new amon-relay for global zone at "8081" (owner=joyent).
      2011-11-10 23:40:43Z WARN: unable to create staging area tmp/db/global: Error: ENOENT, No such file or directory 'tmp/db/global'
      2011-11-10 23:40:43Z DEBUG: Starting app on port 8081 (developer mode)
      2011-11-10 23:40:43Z INFO: Amon-relay listening in global zone at 8081.
      2011-11-10 23:40:43Z WARN: Unable to save new agent probes: Error: ENOENT, No such file or directory 'tmp/db/.6d617f32-4062-4bab-aa15-dfcf8f9e7113'
      2011-11-10 23:40:43Z INFO: Successfully updated agent probes from master (zone: global, md5: undefined -> UaTV7YW3MTyNMX+uguZZZw==).
- review <https://hub.joyent.com/wiki/display/dev/Operating+a+server+fleet>
  How are we doing?
- review and answer MVP points
- JSON api summary at "GET /"
- HTML docs at "GET /docs"
- SNMP traps (per Mark).
  http://tools.ietf.org/html/rfc3877  Alarm MIB
  http://tools.ietf.org/html/rfc3014  Notification Log MIB
  Traps not in snmpjs yet. Keith: """you can however use snmptrapgen, which
  comes with Net-SNMP on our systems it's just a binary program that
  generates traps and directs them somewhere of your choosing. So you can see
  what they look like. That may help you start writing the MIB you want to
  use (definitions of data objects, types, and structures)"""
- https://github.com/davepacheco/kang -ify
- edge-triggered alarms in master for probes
- CA probe type
- probe types: http://circonus.com/why-us/features/monitoring
- compare to http://www.rackspace.com/blog/cloud-monitoring-early-access-program-opens-its-doors/
  http://docs.rackspace.com/cm/api/v1.0/cm-devguide/content/index.html
- revive twilio notification backend as "sms"
- more probe types: run cmd, http check, zone list, ping, disk free, disk
  iops, cpu, mem, ps (aka "top")
    - http://blog.nodeping.com/2012/03/28/ssl-certificate-check/
- torture test on amon-relay resiliency on start
    // XXX Test/design for race condition where: get list of zones, zone
    //     goes down before zsock is created for it. I.e. should be buffering
    //     zoneevents until completed initial setup.
  Amon-relay restarts with lots of zones, while chaos-monkey hup'ing zones.
  Run that for a while then ensure that none of the zones are fubar'd with
  failures to shutdown.
- Interesting services for hooking into, messaging services that might be useful,
  or just general related/competing services:
    - http://aws.amazon.com/cloudwatch/
    - https://www.cloudkick.com/
    - http://www.splunk.com/
    - http://www.pagerduty.com/
    - http://www.opennms.org/ (modcloth using this I think)
    - circonus.com
    - newrelic


# notes: redis

- TODO: test redis being down and down/up/down/up frequently: does that break
  amon-master? It shouldn't.
- TODO: Test a notification going through even if redis is down.
- redis zone config: have "save 60 1". Make sure that isn't filling up disk
  with lots of snapshots. I *presume* this is just one or two files on
  disk, but should check.
- TODO: test how events are handled when redis runs out of memory
  Might want "maxmemory" and "maxmemory-policy ..." or "vm-enabled yes" in
  redis.conf


Ensure do "SELECT 1" (or some value of N) to stay indep of other users of
redis. TODO: Come up with a system for sharing this out. Suggest not using 0
such that any usage of it is an error to trap faulty users.



# Notes: maintenance windows

Related to "suppression" section next.
From MVP:

1.  Ability for customer to set a maintenance window on a monitor (alert
    suppression for a pre-defined period of time).
2.  Ability for operator to set a maintenance window on a CN and on the whole
    cloud. This would disable alerts to operator.

Scope:

- what is scope? Low-level: per zone name and per monitor name. Optionally
  just per monitor name for all applicable zones?
    "Suppress this monitor [until enabled again later]."
    "Suppress this monitor for machines X, Y and Z."
    "Suppress all monitors for machines X, Y and Z."
  Or is this only about suppressing *alarms*? I.e. only at the master-level.
  Yes.
    "Suppress alarms for monitors M and N [until enabled again later]."
    "Suppress alarms for monitor M for N for machines X, Y, and Z."
    "... for the next hour."
  general:
    "Suppress alarms
      for monitors M and N (or all)
      for machines X, Y and Z (or all)
      for a certain amount of time (or until re-enabled)."

Customer endpoints for MVP #1:

    PUT /pub/:login/monitors/:foo/maintenance
          start {RFC date, timestamp, or "now"}
          stop {RFC date, timestamp, <digit>[mhd] (minute, hour, day)}
          notes {String} Short notes on why the maintenance window. Optional.
    DELETE /pub/:login/monitors/:foo/maintenance    # DeleteMonitorMaintenance

Sufficient? This goes to whether to group probes in one or few monitors or
to have many monitors (up to one for each probe). A "monitor" is good for:

- not repeating relevant contacts for one grouping of probes
- grouping alarms: one alarm instance per monitor (mostly)
- logically grouping probes
- setting a maint window once for a group of related probes

A possible addition would be to limit the maint window for a monitor to
a subset of probes. or a subset of machines. The latter more convenient for
the user. Could add a 'targets' or 'machines' field to the maintenance
later to support this.

IOW, let's try the simpler design (maintenance windows on the monitor obj,
no "machines" filter) for now and feel it out.

Special end points for operators for MVP #2: Could this not use the same?
I.e. the operator would just set a maint on their own monitors.


Discussion with Trevor: Maint should be in terms of *machine*, because that
is the user's p.o.v. for doing maintenance. It is possible that a user
would want to drill down and do it by service, which logically might best
map to an Amon *monitor*... or even could be by probe, but don't want to
go to fine grain of probes.

Circonus maint is at the check, Amon probe, level. We won't go there yet.
Just have it at the top-level and can limit only by machine/server.

  POST /pub/:login/maintenance         # CreateMaintenanceWindow
          start {RFC date, timestamp, or "now"}
          stop {RFC date, timestamp, <digit>[mhd] (minute, hour, day)}
          notes {String} Short notes on why the maintenance window. Optional.
          one of:
            all {true}
            machines {Set of machine UUIDs}
            monitors {Set of monitor names}
      Returns:
          :id {Number} incrementing per-user id (a la alarms)

  PUT /pub/:login/maintenance/:id      # UpdateMaintenanceWindow
          ... same fields as above
  DELETE /pub/:login/maintenance/:id   # DeleteMaintenanceWindow


Scenario:

  UUID_MON is a monitor zone setup just to watch other zones.
  UUID1 is our production service box.

  sdc-amon /pub/trent/monitors/mojo/probes/machineup -X PUT -d '{
    type: "machine-up"
    machine: UUID1,
    // This one doesn't accept an agent. The agent this runs on is the
    // compute node GZ for UUID1.
  }'

  sdc-amon /pub/trent/monitors/mojo/probes/ping -X PUT -d '{
    type: "icmp",
    machine: UUID1,     // optional, but necessary to effectively set a maint window on a machine
    agent: UUID_MON,    // UUID of a separate pinger zone
    config: {
      "host": "mo.joyent.com"
    }
  }'

  sdc-amon /agentprobes?agent=UUID

  sdc-amon /pub/trent/maintenance -X POST -d '{
    start: "now",
    stop: "1h",
    machines: ["UUID1"],
    notes: "upgrading this sucka"
  }'

  If allowing 'machine' above to be optional, then also probably want:

    sdc-amon /pub/trent/maintenance -X POST -d '{
      start: "now",
      stop: "1h",
      monitors: ["mojo"],       // <--- set a maint window by monitor
      notes: "upgrading this sucka"
    }'

  Having both is annoying, because you have to show those options in UIs.


Bigger example (TODO: put this as a big use case):

  UUID_MON is our monitor zone
  UUID_DB1 master db zone
  UUID_DB2 slave db zone
  UUID_LB load balancer zone
  UUID_WEBHEAD1 webhead 1 zone
  UUID_WEBHEAD2 webhead 2 zone

  TODO: how to monitor percentiles? E.g. prio1 alarm if 90th percentile
  response time is >200ms or something?

  # Setup a monitor for the service as a whole. Bad news if this one fails,
  # i.e. that's an arg for severities (TODO: severity).
  sdc-amon /pub/trent/monitors/myservice -X PUT -d '{
    contacts: ["email", "sms"],
    severity: 1
  }'
  sdc-amon /pub/trent/monitors/myservice/probes/ping -X PUT -d '{
    type: "icmp",
    agent: UUID_MON,
    config: {
      "host": "myservice.example.com"
    }
  }'
  sdc-amon /pub/trent/monitors/myservice/probes/http -X PUT -d '{
    type: "http",
    agent: UUID_MON,
    config: {
      "host": "http://myservice.example.com/status"
    }
  }'

  # Setup monitors for each of the other machines: is it up? errors in logs?
  # relevant services up? Slightly lower prio. For example, WEBHEAD1:
  sdc-amon /pub/trent/monitors/webhead1 -X PUT -d '{
    contacts: ["email", "sms"],
    severity: 2
  }'
  sdc-amon /pub/trent/monitors/webhead1/probes/machineup -X PUT -d '{
    type: "machine-up"
    machine: UUID_WEBHEAD1,
    // This probe type doesn't accept an agent: it runs from the compute
    // node GZ for `machine`.
  }'
  sdc-amon /pub/trent/monitors/webhead1/probes/ping -X PUT -d '{
    type: "icmp",
    agent: UUID_MON,
    config: {
      "host": "1.2.3.4"
    }
  }'
  sdc-amon /pub/trent/monitors/webhead1/probes/http -X PUT -d '{
    type: "http",
    agent: UUID_MON,
    config: {
      "host": "http://1.2.3.4/status",
      "headers": {
        "Host": "myservice.example.com"
      }
    }
  }'
  sdc-amon /pub/trent/monitors/webhead1/probes/myservice -X PUT -d '{
    type: "smf",    // Not yet implemented
    machine: UUID_WEBHEAD1,
    config: {
      "fmri": "myservice"
    }
  }'
  sdc-amon /pub/trent/monitors/webhead1/probes/logerrors -X PUT -d '{
    type: "log-scan",   // or 'smf-log-scan' if/when that is added
    machine: UUID_WEBHEAD1,
    config: {
      "path": "/var/log/myservice.log",
      "regex": "ERROR"
    }
  }'

  # Might want a lower-prio "maintenance" monitor for each machine.
  # For example, WEBHEAD1:
  sdc-amon /pub/trent/monitors/webhead1maint -X PUT -d '{
    contacts: ["email"],
    severity: 3
  }'
  sdc-amon /pub/trent/monitors/webhead1maint/probes/disk -X PUT -d '{
    type: "disk-free",   // Not yet implemented
    machine: UUID_WEBHEAD1,
    config: {
      "path": "/",        // or call this 'mount'?
      "capacity": 0.8   // alarm if disk usage is over 80%
    }
  }'
  sdc-amon /pub/trent/monitors/webhead1maint/probes/ram -X PUT -d '{
    type: "ram-free",   // Not yet implemented
    machine: UUID_WEBHEAD1,
    config: {
      "capacity": 0.9,   // alarm if RAM usage is over 90% 3 times in 5 minutes
      "threshold": 3,
      "period": 300
    }
  }'

XXX What else? TODO: ask around. Learn about joyent.com setup. Learn about
voxer setup. Ask ops about what kinds of monitoring checks they have setup
typically.


How would I set a maintenance window to upgrade the DB's?
- set maint window on UUID_DB2 (upgrade slave first)
- do upgrades on UUID_DB2
- check monitoring dashboard, if all is well, close the maint window

OR (if don't think about maint window):

- start upgrades on UUID_DB2
- get notification for a db2 monitor alarm, click link to alarm page
- visit alarm page. (This alarm page should include info on other
  recent alarms... highlighting those related to the same machine.)
- "set maintenance window" for this alarm:
  Q: this translates to maint on:
    - that alarm's fault machine(s)?
    - all the machines for that alarm's monitor? no
    - this alarm's monitor
  A: Default to maint on this monitor. Offer to put maint on "all monitors
     for this machine."





Aside: Two classes of probes: remote (runs from the outside, e.g. "ping";
need to specify an 'agent' on which to run) and local (run on that target
machine, e.g. "log-scan", or on its GZ, e.g. "machine-up"). TODO: add this
to documentation.



Transition from machine/server to agent/machine:

    sdc-amon /agentprobes?agent=UUID
      A probe type has a `usesLocalAgent` boolean. If true, then
      `probe.agent = probe.machine`. E.g. 'log-scan' and 'smf'.

    sdc-amon /pub/:login/probe/:probe -X PUT ...
      Q: How to know to check if machine/agent is for a GZ?
      A: Need to have gz=true explicit in probe. Operator check on that.
         Relay must discard probes that don't have correct `gz` value.

      NOTE: Already have probe.global. Use that? No, that's for ProbeType.runInGlobal.
      i.e. runInVmHost.

      probe smartlogin: {
            'machine': prep.headnodeUuid,

            'machineIsPhysical': true,
            'gz': true,
            'machineIsGz': true,
            'machineIsPrivileged': true,
            'machineIsRestricted': true,
            'restricted': true,
            'sudo': true,
            'admin': true,

            'type': 'logscan',
            'config': {
              'path': '/var/svc/log/smartdc-agent-smartlogin:default.log',
              'regex': 'Stopping',
              'threshold': 1,
              'period': 60
            }
          }
        }




Walk through alarm scenarios with maintenance windows:

1. Set a maint window on amontestzone. Then machine-up trips because
   amontestzone is rebooted: Alarm 1. amontestzone comes back up during maint
   window (clears): Alarm 1 is closed. [According to Circ screencast, its
   alarm would not clear until the end of the maint window. Not sure tho.]
   Maint window closes. TODO: `alarm.openedDuringMaintenance=true`.
   TODO: `alarm.closedDuringMaintenance`? or `alarm.clearedDuringMaintenance`.
   TODO: merge "close" and "clear" language?

  GET /pub/:login/updates
    Persistent connection that streams JSON objects of updates to Amon status
    for that user: alarm opened, alarm cleared, alarm closed, maint window
    expired, new event for alarm. Options to filter on these, and throttling.

2. Set a maint window on amontestzone. Machine-up probe trips (only probe
   in that monitor) as zone goes down: Alarm 1. Maint window closes:
   amontestzone is still down. Notification sent for that alarm.
   TODO: add 'reason' code field to `.notify(...)` for the notification
   types to handle the different reasons.

3. Set a maint window on amontestzone. There is a 'mystuff' monitor with
   two probes: 'machine-up' on amontestzone, 'machine-up' on amontestzone2.
   - amontestzone goes down -> Alarm 1 (no notification).
     TODO: might want separate set of "maintFaults" rather than just "faults"
   - amontestzone2 goes down -> attach to Alarm 1, send notification because
     now has a fault not in maint
   - amontestzone comes up (clears)
   - maint window expires: *no* new notification because coming out of
     maint did not add to the set of faults




# Notes: suppression

- suppression facility: global, per monitor, per customer? "per customer"
  could be implemented client side: portal/adminui just sets it for all
  that customer's monitors (looses mixed suppression states).

- suppressing some zone transition events: How?
  - the start + reboot for zone provisioning:
    - talk with Orlando about a "ready" zoneconfig var set by provisioner
  - the stop/start of an intentional reboot (by an operator at the GZ
    command line)
  - intentional reboot or shutdown in adminui
    - either adminui or mapi's shutdown/reboot command would call Amon
      API to suppress?
    - or this is a separate action in adminui to manually suppress
  - intentional reboot or shutdown in portal/cloudapi
    - if MAPI above, then this is done.
  - intentional reboot of the *compute node* for maintenance by operator
    - sdc-amon-suppress command, and/or equivalent in adminui UI.
  - sdc-amon-suppress:
    - one shot?
    - toggle?
    - what is scope? Low-level: per zone name and per monitor name. Optionally
      just per monitor name for all applicable zones?
        "Suppress this monitor [until enabled again later]."
        "Suppress this monitor for machines X, Y and Z."
        "Suppress all monitors for machines X, Y and Z."
      Or is this only about suppressing *alarms*? I.e. only at the master-level.
      Yes.
        "Suppress alarms for monitors M and N [until enabled again later]."
        "Suppress alarms for monitor M for N for machines X, Y, and Z."
        "... for the next hour."
      general:
        "Suppress alarms
          for monitors M and N (or all)
          for machines X, Y and Z (or all)
          for a certain amount of time (or until re-enabled)."


# notes: fma

Use case: operator wants an alert for every zone fault.

- FMA-based check in amon-agent in all CN GZs
  Q: Ask rm how to trigger that FMA event.
- Q: Exclude explicit reboots? What about an explicit reboot, but it doesn't
  come back up?
  A: Yes, exclude for now.
- Q: how to handle clearing an alarm. Does FMA give me an event for that?
  Ditto for non-fma-based zone status watching? Are we going to send an
  amon event for *every* zone running state every minute? No way.


# notes: smartos event streams notes

- sysevent: core element, syseventadm
  https://mo.joyent.com/source/xref/illumos-joyent/usr/src/lib/libsysevent/libsysevent.c#2653
    sysevent_subscribe_event
  Note that zonecfg_notify_* itself calls a slightly different "sysevent_evc_subscribe":
    https://mo.joyent.com/source/xref/illumos-joyent/usr/src/lib/libsysevent/libevchannel.c#566
    https://mo.joyent.com/source/xref/illumos-joyent/usr/src/lib/libzonecfg/common/libzonecfg.c#6692
- zonecfg_notify_bind: uses sysevent, might not need that
  defined here: illumos/usr/src/lib/libzonecfg/common/libzonecfg.c
- fma:
  fmdump
  FMA: http://hub.opensolaris.org/bin/download/Community+Group+fm/WebHome/FMDPRM.pdf
  http://download.oracle.com/docs/cd/E19082-01/819-3196/6n5ed4h40/index.html#indexterm-289
  fminject to test


# notes: events

restore this original sorta-schema for events from Mark?
The (sort of) schema for sending a status update:

      {
        "status": "<STATUS>",
        "message": "Free Form String.",
        "metrics": [{
          "name": "<URN>",
          "type": <TYPE>",
          "value": <VALUE>
        }];
      }

Where:

* <STATUS>: A string, that must be one of `"ok", "warn", "error"`.
* <URN>: The name of the check (note this will be validated against :check).
  An example is something like `urn:cpu:load`.
* <TYPE>: One of `"String", "Integer", "Boolean", "Float"`
* <VALUE>: Value for this metric.  Must correspond to `type`.

If not obvious, you can send multiple metrics per check.



# notes: severity

model Monitor:
  severity: ???

model Probe:
  severity: 1,2,3? circo. has 1-5.

Circonus has severity on the probe equiv.


# notes: alarms

model Alarm:
    user: UUID
    monitor: name, might be null
    name: this is the id for the alarm, see "Alarm id" section below
    timeOpened: when first alarmed
    openedDuringMaint: null or ref to maintenance window? Or just true|false.
    timeClosed: when cleared (auto or explcitly)
    timeLastActivity: (If useful.) This is time of last event or API action
      on this alarm. Perhaps last notification?
    timeLastEvent: Used for de-duping. This is a bit of denorm from `events`
      field.
    timeExpiry: set to N (N == 1 week) after timeClosed whenever it is closed
      This should be useful for portals to show when this will expire.
    suppressNotifications: true|false
    severity: Or could just inherit this from monitor/probe
    isOpen: true|false  (s/isOpen/closed/)
    probes: the *set* of probe *names* from this monitor that have tripped.
    machines: A probe can change, so really want the list of machines
      affected (or really the ones that ran the tripped probes).
    events: ... can't store all events for this so perhaps:
      - firstEvents, recentEvents (N events on either end), numEvents (total)
        Perhaps "N" is 50 here, i.e. something high enough to not be
        common.
      - might want some sort of histogram of events. Can we store a
        timestamp for every event? *Can* we store all events? Not really.
        Can redis help us here?
    numNotifications
      - perhaps also time of last notification? time of first notification.


probe event
  -> handleEvent(event, monitor /* might be null */, probe /* might be null */)
  -> getOrCreateAlarm(event, monitor, probe)  // monitor and probe might be null
      i.e. want alarmFromMonitor ...
      Is there only ever one alarm for a monitor? What if there is an old
      stale (no events for a long time) unclosed alarm for monitor M, then
      a new event comes in? Either is revives that alarm or it creates
      a new one. -> new one (unique names include closed monitors).
      So need threshold on when to break to a new alarm.
      Sep this out to a function that decides of this event "is related"
      to this alarm. For starters this is just whether
      `event.time - alarm.timeLastEvent > 1 hour`. Perhaps expose that
      threshold to the monitor config (`monitor.dedupePeriod`). Later the
      algo could be adaptive or could look at other params (e.g. same probe?
      same zone? similar period of events, i.e. every day at midnight?)
  -> alarm.notify(event, monitor, probe) ?
      There is the first notify, on alarm creation.
      - Modulo "delay" on first notification for transient errors. See
        zabbix and nagios options below.
        "[x] Don't notify on transient error.  Period: [  60] seconds."

      Subsequent events on the same alarm:
      - Dumbest is to notify every time.
      - Notify no more than once per N minutes.
      - Notify every five minutes regardless of additional events.
      - Notify again if higher severity event.
      - ...
      - Zabbix escalation? Don't go there.
      - http://www.zabbix.com/wiki/howto/config/alerts/delaying_notifications
        Nagios "soft states".
        Delay first notification for transient problems. Would NOT want
        for a reboot, but perhaps for a disk size threshold.

      TODO: Email to ops (linda, ben) on what kind of notification and
        re-notification setup they use in prod. If there is anything they'd
        prefer to see. E.g. for repeated failures of a particular
        check/monitor.

      These are attributes of the monitor. What about default? On the user?

      Implementation. How to handle scheduling and reliable
      sending of notifications?
      - put them in redis, have a interval that checks every N seconds for
        a notification to send (perhaps with a .kick() to send right away)
      - actually want to setup a ping for the alarm to see about notifying.
        So an alarm could handle this itself with setTimeout. If it is to
        be delayed, then it is up to that Alarm instance to put it in redis
        in case of restarts.

      So not `alarm.notify(...)` but `alarm.start()`. Is it too much to have
      an alarm in memory the whole time? Yes. So not managed by each alarm
      instance.

      Could it be "active alarms"? I.e. reminder notifications time out
      if not new events on an alarm. Or just not support reminder
      notifications (for now). Punt on "delay for transient" failure for now
      too. That means no timer needed.

Implementation (take 2):
probe event
  -> app.processEvent(event)
    Get `monitor` and `probe`.
    Get or create new Alarm: alarm.
    app.attachEventToAlarm(alarm, event, ...)
  -> app.getOrCreateAlarm(event, user, monitor, probe, function (err, alarm))
    - Get all open alarms for this user/monitor.
    - If not any -> create new alarm.
    - Pass all potential alarms to app.chooseRelatedAlarm().
    - If alarm -> return alarm
    - Else -> create new alarm.
  -> app.chooseRelatedAlarm(alarms, event, user, monitor, probe, function(err, alarm))
    First pass at this: Choose the alarm with the most recent `timeLastEvent`.
    If `event.time - alarm.timeLastEvent > 1 hour` then return none, i.e.
    not related. Else, return that alarm.
    Eventually make this "1 hour" an optional var on monitor.
    Eventually this algo can consider more vars.
  -> app.createAlarm(alarm, event, monitor)
    uuid: uuid()
    monitor:
  -> app.alarmAddEvent(alarm, event, ...)
    - update alarm fields:
        timeOpened: when first alarmed
        timeLastActivity: (If useful.) This is time of last event or API action
          on this alarm. Perhaps last notification?
        timeLastEvent: Used for de-duping. This is a bit of denorm from `events`
          field.
        severity: Or could just inherit this from `monitor`
        isOpen: true|false
        probes: the *set* of probe *names* from this monitor that have tripped.
        machines: A probe can change, so really want the list of machines
          affected (or really the ones that ran the tripped probes).
        events: ... can't store all events for this so perhaps:
          - firstEvents, recentEvents (N events on either end), numEvents (total)
            Perhaps "N" is 50 here, i.e. something high enough to not be
            common.
          - might want some sort of histogram of events. Can we store a
            timestamp for every event? *Can* we store all events? Not really.
            Can redis help us here?
    - Decide whether to notify:
      - if this is a clear event (XXX probe event needs a 'clear: true'
        field, set by machine-up 'up' event) and never opened, then no
      - if in maint, then no (update 'openedDuringMaint')
      - ... more?
      - else, notify:
          numNotifications



.
