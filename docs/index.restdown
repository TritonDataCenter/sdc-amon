---
title: Amon (SDC Monitoring and Alarming)
markdown2extras: wiki-tables, code-friendly, cuddled-lists
apisections: Master API: Monitors, Master API: Probes, Master API: Alarms, Master API: Miscellaneous, Relay API
---

# Amon (SDC Monitoring and Alarming)

*Note: This document is intended for an SDC operator or developer. End-user
docs for SDC monitoring and alarming are part of the Cloud API
documentation.*

Amon is a monitoring and alarming system for SmartDataCenter (SDC). It has
three components: a central master, a relay agent ("amon relay") in each
node global zone agents ("amon agent") in global zones and, eventually, in
customer zones and guest VMs. **Monitors** (grouping of probes and contacts)
and **probes** (things to check and alarm on) are configured on the master
(i.e. on the "Amon Master API"). Probe data is passed from the master, via
the relays to the appropriate agent where the probe is run. When a probe
fails/trips it raises and event, which passes through the relays up to the
master. The master handles events by creating or updating **alarms** and
sending notifications to the configured contacts, if appropriate (suppression
and de-duplication rules can mean a notification is not always sent). Contact
info lives with the user account in UFDS.

For external users (i.e. anyone other than an Amon developer), it is the Amon
Master API (or "Amon API" for short) that is most relevant. This document
also describes the (internal) Relay API.

Public endpoints of the Amon Master API are under a "/pub" prefix to
facilitate proxying to Cloud API. For example, the set of open alarms for an
user is:

    GET  /pub/:user/monitors           # Amon Master API
    GET  /:login/monitors              # Cloud API

Where ":user" is typically a user UUID. However, for convenience in
development, ":user" may also be a user's login string.

**Warning: Amon does no authorization (or authentication). That's up to Cloud
API.**


### Error Responses

If you get back any error code in the 4xx range, you will receive a formatted
error message of the scheme:

    {
      "code": "CODE",
      "message": "human readable string"
    }

Where the code element is one of:

* InvalidArgument
* InvalidHeader
* MissingParameter
* RequestTooLarge
* ResourceNotFound
* UnknownError
* any of the errors from <http://ldapjs.org/errors.html>

Clients are expected to check HTTP status code first, and if in the 4xx range,
they can leverage the codes above.

TODO: complete the error list above, show some examples



# Master API: Monitors

A monitor is the primary object for defining what and how to monitor and
who should be notified on alarms. A monitor holds a reference to
contacts to notify. A set of probes to run (e.g. check for N occurrences of
"ERROR" in "/var/foo/bar.log" in a minute) are added to a monitor.

## ListMonitors (GET /pub/:user/monitors)

List all monitors for this user.

### Inputs

None.

### Returns

An array of monitor objects. Keys are:

||name||String||Name of this monitor. This is the unique identifier for this monitor. It must be 1-32 chars, begin with alpha character and include only alphanumeric '_', '.' and '-' ||
||contacts||Array||Set of contact names that are to be notified when this monitor alarms.||

### Errors

TODO

### Example

    $ sdc-amon /pub/hamish/monitors
    HTTP/1.1 200 OK
    Connection: close
    Date: Tue, 08 Nov 2011 00:38:54 GMT
    Server: Amon Master/1.0.0
    X-Api-Version: 1.0.0
    X-Request-Id: addcc1ab-cdd2-4961-b4f8-b44a7ab2a31a
    X-Response-Time: 491
    Content-Length: 42
    Content-MD5: 3/3Q0/Mz/37AHee5JHHJ1Q==
    Content-Type: application/json
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Methods: OPTIONS, GET
    Access-Control-Allow-Headers: Accept, Content-Type, Content-Length, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time

    [
      {
        "name": "mysql",
        "contacts": [
          "cellPhone"
        ]
      }
    ]


## GetMonitor (GET /pub/:user/monitors/:monitor)

TODO

## PutMonitor (PUT /pub/:user/monitors/:monitor)

TODO

## FakeMonitorFault (POST /pub/:user/monitors/:monitor?action=fakefault)

Fake a fault on this monitor. This will send in fake event for this monitor.
Typically this will result in creation of an alarm and sending a notification
to all contacts for this monitor (depending on current suppression rules).

### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID (from UFDS) or username ('login' in UFDS)||
||monitor (in URL)||String||The monitor name.||
||action||String||"fakefault"||
||clear||String||Optional. Use "true" to send a "clear" event. This should typically clear an alarm created by a previous fake fault call.||

### Example

    $ sdc-amon /pub/admin/monitors/sdczones?action=fakefault -X POST
    HTTP/1.1 200 OK
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Headers: Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time
    Server: Amon Master/1.0.0
    X-Request-Id: 9fb2a9f3-f34d-4261-ac86-985dc376c442
    Access-Control-Allow-Methods: POST
    Connection: close
    Content-Length: 16
    Content-MD5: c2PoX+nt7m8FOksxlYjAhg==
    Content-Type: application/json
    Date: Wed, 07 Mar 2012 09:23:31 GMT
    X-Response-Time: 479

    {
      "success": true
    }

## DeleteMonitor (DELETE /pub/:user/monitors/:monitor)

TODO





# Master API: Probes

A monitor has one or more probes. A "probe" is a single thing to check
or watch for.

## ListProbes (GET /pub/:user/monitors/:monitor/probes)

TODO

### Example

    $ sdc-amon /pub/hamish/monitors/whistle/probes
    HTTP/1.1 200 OK
    Connection: close
    Date: Tue, 22 Nov 2011 17:59:22 GMT
    Server: Amon Master/1.0.0
    X-Api-Version: 1.0.0
    X-Request-Id: c92e87c6-8da1-4f67-b85e-f4458340642b
    X-Response-Time: 760
    Content-Length: 407
    Content-MD5: 5EdOGXW+sKRtRajFf+ajkw==
    Content-Type: application/json
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Methods: OPTIONS, GET
    Access-Control-Allow-Headers: Accept, Content-Type, Content-Length, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time

    [
      {
        "name": "whistlelog",
        "user": "7b23ae63-37c9-420e-bb88-8d4bf5e30455",
        "monitor": "whistle",
        "machine": "global",
        "type": "logscan",
        "config": {
          "path": "/tmp/whistle.log",
          "regex": "tweet",
          "threshold": 2,
          "period": 60
        }
      },
      {
        "name": "whistlelog2",
        "user": "7b23ae63-37c9-420e-bb88-8d4bf5e30455",
        "monitor": "whistle",
        "machine": "global",
        "type": "logscan",
        "config": {
          "path": "/tmp/whistle2.log",
          "regex": "tweet",
          "threshold": 1,
          "period": 60
        }
      }
    ]


## GetProbe (GET /pub/:user/monitors/:monitor/probes/:probe)

TODO

## PutProbe (PUT /pub/:user/monitors/:monitor/probes/:probe)

TODO: mention 'agent' as required and suggested. 'machine' is an optional
value useful for maintenance windows. It is implied for 'runLocally' probe
types.

## DeleteProbe (DELETE /pub/:user/monitors/:monitor/probes/:probe)

TODO



# Master API: Alarms

An alarm is an occurence of a problem situation. Typically an alarm is
associated with a particular monitor. An alarm is opened when one of the
monitor's probes trips. Some probe types (e.g. "machine-up") support
clearing alarms automatically (e.g. when a machine being watched by a
"machine-up" probe comes back up after having been down, it will clear
the alarm for it having been down). Other alarms need to be explicitly
closed.

These APIs provide info on recent alarms for a user. Closed alarms are
only guaranteed to be persisted for a week. I.e. this is mainly about showing
open (i.e. unresolved) alarm situations.

The point of an "alarm" object is (a) to have a persistent object to show
current open alarms (e.g. for Cloud API, Operator Portal and Customer Portal);
(b) for the master to handle de-duplication, i.e. avoid a flood
of duplicate notifications for a stream of events relating to the same
problem; and (c) to support the user suppressing notifications for this
alarm ("Yah, I know it is a problem, but I can't deal with it right now.").



### Alarm Fields

||**Field**||**Type**||**Description**||
||user||String||The UUID of the user to which this alarm belongs.||
||id||Integer||The integer ID of this alarm. Note that this is scoped on `user`.||
||monitor||String||The name of the monitor with which this alarm is associated.||
||closed||Boolean||Whether this alarm has been closed.||
||suppressed||Boolean||Whether notifications for this alarm are currently suppressed.||
||timeOpened||Integer||Timestamp (milliseconds since the epoch) at which the alarm was opened.||
||timeClosed||Integer||Timestamp (milliseconds since the epoch) at which the alarm was closed.||
||timeLastEvent||Integer||Timestamp (milliseconds since the epoch) at which the last event for this alarm occurred.||
||v||Integer||The version of this Alarm object schema. Currently this is only exposed via the internal APIs.||

An example alarm:

    {
      "user": "deadbeef-5555-5555-5555-555555555555",
      "id": "1",
      "monitor": "isup",
      "closed": false,
      "timeOpened": 1332870155860,
      "timeClosed": null,
      "timeLastEvent": 1332870615162,
      "numNotifications": 0,
      "v": 1
    }


## ListAllAlarms (GET /alarms)

An **internal** API for listing and searching all alarms. This is intended
for operators and development/debugging only. In a heavily loaded system care
should be taken with this endpoint to not swamp the Amon Master.

### Inputs

None.

### Errors

For all possible errors, see [Error Response](#error-responses) above.

### Returns

Returns an array of alarms (see [Alarm Fields](#alarm-fields) above).

### Example

    $ sdc-amon /alarms
    HTTP/1.1 200 OK
    ...

    [
      {
        "user": "deadbeef-5555-5555-5555-555555555555",
        "id": "1",
        "monitor": "isup",
        "closed": false,
        "timeOpened": 1332870155860,
        "timeClosed": null,
        "timeLastEvent": 1332870615162,
        "numNotifications": 0,
        "v": 1
      }
    ]


## ListAlarms (GET /pub/:user/alarms)

List a users alarms. By default this is the set of open alarms and recently
closed (in the last hour) alarms, if any. Note that old closed alarms are
automatically expunged (currently a week after being closed).

### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID (from UFDS) or username ('login' in UFDS)||
||state||String||One of "recent" (open and recently closed alarms, this is the default), "open" and "closed".||
||monitor||String||Only return alarms associated with this monitor.||

### Errors

For all possible errors, see [Error Response](#error-responses) above.

||**Error Code**||**HTTP Code**||**Description**||
||InvalidArgumentError||400||If `state` or `monitor` is invalid.||

### Returns

Returns an array of alarms (see [Alarm Fields](#alarm-fields) above).

### Example

    $ sdc-amon /pub/bob/alarms?state=open
    HTTP/1.1 200 OK
    ...

    [
      {
        "user": "deadbeef-5555-5555-5555-555555555555",
        "id": "1",
        "monitor": "isup",
        "closed": false,
        "timeOpened": 1332870155860,
        "timeClosed": null,
        "timeLastEvent": 1332870615162,
        "numNotifications": 0,
        "v": 1
      }
    ]


## GetAlarm (GET /pub/:user/alarms/:alarm)

Get a particular alarm.

### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID (from UFDS) or username ('login' in UFDS)||
||alarm (in URL)||Integer||The alarm id for this user.||

### Returns

An alarm object (see [Alarm Fields](#alarm-fields) above).

### Errors

For all possible errors, see [Error Response](#error-responses) above.

||**Error Code**||**HTTP Code**||**Description**||
||ResourceNotFound||404||If `user` does not exist or the `alarm` id does not exist.||
||Gone||410||If the `alarm` has been expunged. Closed alarms are expunged after about a week.||

### Example

    $ sdc-amon /pub/bob/alarms/1
    HTTP/1.1 200 OK
    ...

    {
      "user": "deadbeef-5555-5555-5555-555555555555",
      "id": "1",
      "monitor": "isup",
      "closed": false,
      "timeOpened": 1332870155860,
      "timeClosed": null,
      "timeLastEvent": 1332870615162,
      "numNotifications": 0,
      "v": 1
    }


## CloseAlarm (POST /pub/:user/alarms/:alarm?action=close)

Close the given alarm.

### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID (from UFDS) or username ('login' in UFDS)||
||alarm (in URL)||Integer||The alarm id for this user.||
||action||String||"close". See other "*Alarm*" actions in this section.||

### Returns

Nothing. Responds with an HTTP 202 (Accepted) on success.

### Errors

For all possible errors, see [Error Response](#error-responses) above.

||**Error Code**||**HTTP Code**||**Description**||
||ResourceNotFound||404||If `user` does not exist or the `alarm` id does not exist.||
||Gone||410||If the `alarm` has been expunged. Closed alarms are expunged after about a week.||

### Example

    $ sdc-amon /pub/bob/alarms/123?action=close -X POST
    HTTP/1.1 202 Accepted
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Headers: Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time
    Server: Amon Master/1.0.0
    X-Request-Id: e16b7aab-b8b8-4a8a-97f2-9216dd0e5798
    Access-Control-Allow-Methods: POST
    Connection: close
    Content-Length: 0
    Date: Mon, 02 Apr 2012 17:15:52 GMT
    X-Response-Time: 3



## ReopenAlarm (POST /pub/:user/alarms/:alarm?action=reopen)

Re-open the given alarm. This exists mainly to provide an "undo" for an
accidental "close" action.

### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID (from UFDS) or username ('login' in UFDS)||
||alarm (in URL)||Integer||The alarm id for this user.||
||action||String||"reopen". See other "*Alarm*" actions in this section.||

### Returns

Nothing. Responds with an HTTP 202 (Accepted) on success.

### Errors

For all possible errors, see [Error Response](#error-responses) above.

||**Error Code**||**HTTP Code**||**Description**||
||ResourceNotFound||404||If `user` does not exist or the `alarm` id does not exist.||
||Gone||410||If the `alarm` has been expunged. Closed alarms are expunged after about a week.||

### Example

    $ sdc-amon /pub/bob/alarms/123?action=reopen -X POST
    HTTP/1.1 202 Accepted
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Headers: Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time
    Server: Amon Master/1.0.0
    X-Request-Id: e16b7aab-b8b8-4a8a-97f2-9216dd0e5798
    Access-Control-Allow-Methods: POST
    Connection: close
    Content-Length: 0
    Date: Mon, 02 Apr 2012 17:15:52 GMT
    X-Response-Time: 3



## SuppressAlarmNotifications (POST /pub/:user/alarms/:alarm?action=suppress)

Suppress notifications for events on the given alarm.

### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID (from UFDS) or username ('login' in UFDS)||
||alarm (in URL)||Integer||The alarm id for this user.||
||action||String||"suppress". See other "*Alarm*" actions in this section.||

### Returns

Nothing. Responds with an HTTP 202 (Accepted) on success.

### Errors

For all possible errors, see [Error Response](#error-responses) above.

||**Error Code**||**HTTP Code**||**Description**||
||ResourceNotFound||404||If `user` does not exist or the `alarm` id does not exist.||
||Gone||410||If the `alarm` has been expunged. Closed alarms are expunged after about a week.||

### Example

    $ sdc-amon /pub/bob/alarms/123?action=suppress -X POST
    HTTP/1.1 202 Accepted
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Headers: Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time
    Server: Amon Master/1.0.0
    X-Request-Id: e16b7aab-b8b8-4a8a-97f2-9216dd0e5798
    Access-Control-Allow-Methods: POST
    Connection: close
    Content-Length: 0
    Date: Mon, 02 Apr 2012 17:15:52 GMT
    X-Response-Time: 3



## UnsuppressAlarmNotifications (POST /pub/:user/alarms/:alarm?action=unsuppress)

Stop suppression of notifications on the given alarm.

### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID (from UFDS) or username ('login' in UFDS)||
||alarm (in URL)||Integer||The alarm id for this user.||
||action||String||"close". See other "*Alarm*" actions in this section.||

### Returns

Nothing. Responds with an HTTP 202 (Accepted) on success.

### Errors

For all possible errors, see [Error Response](#error-responses) above.

||**Error Code**||**HTTP Code**||**Description**||
||ResourceNotFound||404||If `user` does not exist or the `alarm` id does not exist.||
||Gone||410||If the `alarm` has been expunged. Closed alarms are expunged after about a week.||

### Example

    $ sdc-amon /pub/bob/alarms/123?action=unsuppress -X POST
    HTTP/1.1 202 Accepted
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Headers: Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time
    Server: Amon Master/1.0.0
    X-Request-Id: e16b7aab-b8b8-4a8a-97f2-9216dd0e5798
    Access-Control-Allow-Methods: POST
    Connection: close
    Content-Length: 0
    Date: Mon, 02 Apr 2012 17:15:52 GMT
    X-Response-Time: 3


## DeleteAlarm (DELETE /pub/:user/alarms/:alarm)

Delete the given alarm. This is more severe than [*closing* an
alarm](#CloseAlarm) and typically should not be something a user is doing.
At least for first blush I'd suggest *not* exposing this to the user.


### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID (from UFDS) or username ('login' in UFDS)||
||alarm (in URL)||Integer||The alarm id for this user.||

### Returns

Nothing. Responds with an HTTP 204 (Accepted) on success.

### Errors

For all possible errors, see [Error Response](#error-responses) above.

||**Error Code**||**HTTP Code**||**Description**||
||ResourceNotFound||404||If `user` does not exist or the `alarm` id does not exist.||

### Example

    $ sdc-amon /pub/bob/alarms/123 -X DELETE
    HTTP/1.1 204 No Content
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Headers: Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time
    Server: Amon Master/1.0.0
    X-Request-Id: 727e929a-d735-c748-96ae-5e2762764531
    Access-Control-Allow-Methods: DELETE
    Connection: close
    Content-Length: 0
    Date: Mon, 02 Apr 2012 17:15:52 GMT
    X-Response-Time: 3



# Master API: Maintenance Windows

On can set maintenance windows on monitors (or on machines) to temporarily
suppress notifications for probe failures.

### Maintenance Window Fields

||**Field**||**Type**||**Description**||
||user||UUID||The UUID of the user to which the maintenance window belongs.||
||id||Integer||A unique (to this user) integer id for this maintenance window.||
||start||timestamp||A timestamp at which this maintenance window starts.||
||end||timestamp||A timestamp at which this maintenance window ends.||
||notes||String||The given "notes". This key is excluded if there are no notes.||
||all||Boolean||"true", if this maintenance window applies to all monitors.||
||monitors||Array||Array of monitor names to which this maintenance window applies, if any.||
||machines||Array||Array of machine UUIDs to which this maintenance window applies, if any.||

Only one of `all`, `monitors`, `machines` will exist.

An example maintenance window:

    XXX


## ListAllMaintenanceWindows (GET /maintenances)

An **internal** API for listing and searching all maintenance windows. This
is intended for operators and development/debugging only. In a heavily loaded
system care should be taken with this endpoint to not swamp the Amon Master.

### Inputs

None.

### Errors

For all possible errors, see [Error Response](#error-responses) above.

### Returns

Returns an array of maintenance windows (see
[Maintenance Window Fields](#maintenance-window-fields) above).

### Example

    $ sdc-amon /maintenances
    HTTP/1.1 200 OK
    ...

    XXX


## ListMaintenanceWindows (GET /pub/:user/maintenances)

XXX


## GetMaintenanceWindow (POST /pub/:user/maintenances/:maintenance)

XXX


## CreateMaintenanceWindow (POST /pub/:user/maintenances)

Create a maintenance window.

### Inputs

||**Parameter**||**Required?**||**Default**||**Description**||
||user (in URL)||Required||-||The user UUID (from UFDS) or username ('login' in UFDS)||
||start||Required||-||The time at which the maintenance window starts. RFC date, timestamp, or "now".||
||end||Required||-||The time at which the maintenance window ends. RFC date, timestamp, or "<digit>[mhd]" (minute, hour, day). E.g.: "1d" means one day.||
||notes||Optional||-||Short notes on why this maintenance window.||
||all||Optional||-||A boolean. Set to "true" to indicate that the maintenance window should apply to all monitors.||
||monitors||Optional||-||A comma-separated list of monitor names to which the maintenance window applies.||
||machines||Optional||-||A comma-separated list of machine UUIDs to which the maintenance window applies.||

One of `all`, `monitors` or `machines` must be supplied.

### Returns

Returns a maintenance window object (see
[Maintenance Window Fields](#maintenance-window-fields) above).

### Errors

For all possible errors, see [Error Response](#error-responses) above.

### Example

    $ sdc-amon /pub/bob/maintenance -X POST -d start=now -d end=1d \
        -d monitors=mymonitor
    XXX


## DeleteMaintenanceWindow (DELETE /pub/:user/maintenances/:maintenance)

XXX



# Master API: Miscellaneous

## Ping (GET /ping)

A simple ping to check to health of the Amon server. Here "pid" is the PID of
the Amon master server process. This is helpful for the test suite.

### Inputs

||**Field**||**Type**||**Description**||
||error||String||Optional. An error code name, e.g. "ResourceNotFound" to simulate an error response.||
||message||String||Optional. The error message to include in the simulated error response. Defaults to "pong".||

### Returns

When not simulating an error response, a "pong" object is returned:

||**Field**||**Type**||**Description**||
||ping||String||"pong"||
||pid||String||The PID of Amon Master process.||

When simulating an error, the HTTP response code depends on the error type
and the response body is an JSON object with:

||**Field**||**Type**||**Description**||
||code||String||Error code string.||
||message||String||Error message.||

### Examples

    $ sdc-amon /ping
    HTTP/1.1 200 OK
    Connection: close
    Date: Wed, 02 Nov 2011 04:40:42 GMT
    Server: Amon Master/1.0.0
    X-Api-Version: 1.0.0
    X-Request-Id: 265a6379-bbf5-4d86-bd11-5e96614035d8
    X-Response-Time: 2
    Content-Length: 15
    Content-MD5: tBwJDpsyo/hcYx2xrziwrw==
    Content-Type: application/json
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Methods: OPTIONS, GET
    Access-Control-Allow-Headers: Accept, Content-Type, Content-Length, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time

    {
      "ping": "pong"
      "pid": 1234
    }

Ping can also be used to simulate error responses from Amon master:

    $ sdc-amon /ping?error=ResourceNotFound\&message=nada
    HTTP/1.1 404 Not Found
    Connection: close
    Date: Tue, 06 Dec 2011 23:43:03 GMT
    Server: Amon Master/1.0.0
    X-Api-Version: 1.0.0
    X-Request-Id: 849950cf-e9de-452b-9640-6f4c7da053e2
    X-Response-Time: 2
    Content-Length: 44
    Content-MD5: /vxoedHxPf+L11uaQ8bkJQ==
    Content-Type: application/json
    Access-Control-Allow-Origin: *
    Access-Control-Allow-Methods: OPTIONS, GET
    Access-Control-Allow-Headers: Accept, Content-Type, Content-Length, Date, X-Api-Version
    Access-Control-Expose-Headers: X-Api-Version, X-Request-Id, X-Response-Time

    {
      "code": "ResourceNotFound",
      "message": "nada"
    }



## GetUser (GET /pub/:user)

Get information for the given user. This is not an essential part of
the API, **should NOT be exposed publicly (obviously)**, and can be removed
if not useful.

### Inputs

||**Field**||**Type**||**Description**||
||user (in URL)||String||The user UUID or login||

### Example

    $ sdc-amon /pub/7b23ae63-37c9-420e-bb88-8d4bf5e30455
    HTTP/1.1 200 OK
    ...

    {
      "login": "hamish",
      "email": "hamish@joyent.com",
      "id": "7b23ae63-37c9-420e-bb88-8d4bf5e30455",
      "firstName": "Hamish",
      "lastName": "MacHamish"
    }


## GetState (GET /state)

Return internal state. **Note:** eventually this will probably migrate to
[Kang](https://github.com/davepacheco/kang).

### Inputs

None.

### Example

    $ sdc-amon /state
    HTTP/1.1 200 OK
    ...

    {
      "cache": {
        "user": {
          "name": "user",
          "expiry": 300000,
    ...


## DropCaches (POST /state?action=dropcaches)

Drop in-process caches. This is important for running the test suite against
a live Amon Master as a pre-existing cache can influence some of the test
cases.

### Inputs

||**Field**||**Type**||**Description**||
||action||String||"dropcaches"||

### Example

    $ sdc-amon /state?dropcaches -X POST
    HTTP/1.1 202 Accepted
    ...



# Relay API

Amon employs a tree of relay servers for (a) ferrying agent probe data
from the master to the agents and (b) ferrying events from agents back to
the master. This is done via the Relay API. The Amon Master also implements
this API.

Dev Note: The module "common/lib/relay-client.js" is used by both amon-relay
and amon-master to speak the Relay API. In production usage the relays
speak to the master over a network socket and agents speak to their relay
over a Unix domain socket (zsocket).


## AddEvents (POST /events)

Sends one or more events up to a relay (or the Amon master). Agents run
the given probes and send an event when a probe test trips/fails.

TODO


## ListAgentProbes (GET /agentprobes)

Amon Relays periodically get agent control data (probes to run on a
particular agent) from the master. From there, agents poll their relay for
this control data.

Note: The returned probes are sorted to ensure a stable order and hence a
stable "Content-MD5" header to use for caching.

### Inputs

||**Parameter**||**Required?**||**Default**||**Description**||
||agent||Required||-||The agent UUID. Note that the agent UUID is that of the machine -- VM, SmartMachine (aka zone), or physical node -- on which is runs.||


### Returns

An array of probe objects, which contain:

TODO

### Errors

TODO


## HeadAgentProbes (HEAD /agentprobes)

This "HEAD" form of `ListAgentProbes` allows for relays and agents to check
for agent control data changes with less network overhead.

### Inputs

||**Parameter**||**Required?**||**Default**||**Description**||
||agent||Required||-||The agent UUID. Note that the agent UUID is that of the machine -- VM, SmartMachine (aka zone), or physical node -- on which is runs.||



# Master Configuration

Reference docs on configuration vars to amon-master. Default values are in
"master/factory-settings.json". Custom values are provided in a JSON file
passed in with the "-f CONFIG-FILE-PATH" command-line option.

Note that given custom values override full top-level keys in the factory
settings. For example: if providing 'userCache', one must provide the
whole userCache object.

||port||Port number on which to listen.||
||ufds.url||LDAP URL to connect to UFDS.||
||ufds.rootDn||UFDS root dn.||
||ufds.password||UFDS root dn password.||
||ufds.caching||Boolean indicating if UFDS caching should be enabled. Default true.||
||mapi.url||MAPI client url.||
||mapi.username||MAPI HTTP admin username.||
||mapi.password||MAPI HTTP admin password.||
||redis.host||Redis server host or IP. Defaults to 127.0.0.1 if not given.||
||redis.port||Redis server port. Defaults to 6379 if not given.||
||userCache.size||The number of entries to cache.||
||userCache.expiry||The number of seconds for which cache entries are valid.||
||notificationPlugins||An object defining all notification mechanisms. This is a mapping of plugin name, e.g. "email" or "sms", to plugin data.||
||notificationPlugins.NAME.path||A node `require()` path from which the Amon master can load the plugin module, e.g. "./lib/twillio".||
||notificationPlugins.NAME.config||An object with instance data for the plugin.||



# Probe Types

TODO:XXX describe local v. remote probe types here and implications with
agent/machine args for creation. Note remote/local on each probe section
below.


## Probe: logscan

Watch (tail -f) a log file for a particular pattern (regular expression).

### Config

||**Parameter**||**Required?**||**Default**||**Description**||
||path||Required||-||Path to the log file to watch.||
||regex||Required||-||Regular expression pattern to match against each log line.||
||period||Optional||60||Integer number of seconds. Time window in which `threshold` number of matches must be found to alarm.||
||threshold||Optional||1||Integer. Number of times a match must be found within `period` to alarm.||

### Example

    $ sdc-amon /pub/bob/monitors/mymonitor/probes/myservice -X PUT --data '{
        "type": "logscan",
        "machine": "444d70d5-0187-e5d4-468f-7b49a6b014ff",
        "config": {
            "path": "/var/log/myservice.log",
            "regex": "ERROR",
            "threshold": 1,
            "period": 60
        }
    }'

## Probe: machine-up

Watch for a machine (i.e. a virtual machine) going up or down. Alarms for
this probe will "clear", i.e. an alarm created for a machine going down
will be automatically closed by the event sent when the machine comes back
up.

### Config

None.

### Example

    $ sdc-amon /pub/bob/monitors/mymonitor/probes/mywebhead -X PUT --data '{
        "type": "machine-up",
        "machine": "a5134e62-1bed-5e48-a760-7b9b79aef729"
    }'

## Probe: http

Watches a HTTP(S) URL for a specific body (regex), or status codes.

### Config

||**Parameter**||**Required?**||**Default**||**Description**||
||url||Required||-||URL to probe, this url must be accessable from the machine or server running the probe||
||method||Optional||GET||Curently Supports GET (default) or POST||
||headers||Optional||-||Additional headers to include with request (an object)||
||body||Optional||-||string of form data||
||username||Optional||-||Username used for HTTP Basic Auth||
||password||Optional||-||Password used for HTTP Basic Auth||
||interval||Optional||90||interval in seconds to check the specified URL||
||period||Optional||300||Integer number of seconds. Time window in which `threshold` number of matches must be found to alarm.||
||threshold||Optional||1||Integer. Number of times a match must be found within `period` to alarm.||
||maxResponseTime||Optional||-||When response time (ms) exceeds `maxResponseTime`, an event will fire||
||timeout||Optional||30||Maximum time in seconds that you allow the connection to the server to take.||
||regex.pattern||Optional||-||check the response body for the regex pattern, if there are no matches, an event is fired||
||regex.flags||Optional||-||flags to use with `regex.pattern` (ie `g` for global matching, `i` to ignore case sensitivity||
||statusCodes||Optional||[200,201,202,204]||an array of status codes to be compared to the response, if statusCodes does not contain include the response status code form the request, then an alarm is fired||

### Example

Watches http://google.com/ home page and fire when a non 2xx status code is returned

    $ sdc-amon /pub/bob/monitors/mymonitor/probes/googleprobe -X PUT --data '{
        "type": "http",
        "machine": "a5134e62-1bed-5e48-a760-7b9b79aef729",
        "config":{
          "url":"http://google.com/"
        }
    }'

## Probe: icmp

Performs an ICMP ping to a specific host and alarms when there are signs of
packet loss

### Config

||**Parameter**||**Required?**||**Default**||**Description**||
||host||Required||-||the host to check, ie `4.2.2.1`, or `example.com`||
||npackets||Optional||5||number of packets to send per check||
||interval||Optional||90||interval in seconds to check the specified host||
||period||Optional||300||Integer number of seconds. Time window in which `threshold` number of matches must be found to alarm.||
||threshold||Optional||1||Integer. Number of times packet loss is encountered within `period` before alarming||

### Example

Ping api.us-west.joyent.com periodically and alarm in case of network
interuptions or packet loss.

    sdc-amon /pub/admin/monitors/ping/probes/ping -X PUT --data '
    {
      "type":"icmp",
      "server":"564da583-a93e-7fe7-5d61-5c3190ba44fb",
      "config": {
        "host":"api.us-west.joyent.com"
      }
    }'


# Event Types

This is internal reference data. An Amon user shouldn't need to know
these details.

**WARNING: This is incomplete and underspecified.**

Current event layouts (working on a spec for this). Event from logscan
probe type (a "probe event"):

    {
      "v":1,
      "type": "probe",
      "user": "44444444-4444-4444-4444-444444444444",
      "monitor": "gz",
      "probe": "smartlogin",
      "probeType": "logscan"
      "clear": false,
      "data":{
        "message":"Log \"/var/svc/log/smartdc-agent-smartlogin:default.log\" matched /Stopping/.",
        "value":1,
        "details":{
          "match":"[ Mar 7 01:01:19 Stopping because service restarting. ]\n[ Mar 7 01:01:19 Executing stop method (:kill). ]"
        }
      },
      "machine": UUID1,    // only from some probe types

      // Added by relay:
      "uuid":"1e5933ba-c813-44fc-bb54-8b75ebf53eff" // unique event UUID
      "time": 1331782620613,
      "agent": UUID2,
      "relay": UUID3,
    }

Test event from "POST /pub/:user/monitors/:monitor?action=fakefault"
(a "test event" or a "monitor event", i.e. associated with a monitor):

    {
      v: 1,
      time: Date.now(),
      type: "fake",
      user: UUID,
      monitor: NAME
      clear: CLEAR,
      data:{
        message: "Test notification.",
      },
      uuid: uuid()
    }

Other potential event types:

- "operator event": send to (Amon) operator for some internal Amon problem
- "user event": send to user for some configuration problem in their data?
  E.g. I was think that with groups, notify the group owner if can't contact
  one of the group members. Not sure though.
- "relay" event? A problem report from a relay? Perhaps this is just an
  operator event? Not sure.



# MVP

Roughly said:

"The absolute MVP for Monitoring is having the ability to alert when a
VM or Zone goes down, and the ability to alert someone via email."

More detail:

- Only necessary alert medium: email.
  *Done. Email notification type.*
- Ability to alert operator when a machine goes down.
  *Done. "machine-up" probe type. There are remaining tickets for avoiding
  alarms for intentional reboots, etc.*
- Ability to alert operator when that machine comes back up (aka a "clear" or "ok").
  *Done. "machine-up" probes will clear.*
- Ability to alert customer when their machine goes down.
  Option to distinguish between going down for a fault (FMA) or any reason
  (includes intentional reboots).
  *Q: Where does the reboot of a full CN fit in here?*
  *"machine-up" probe type works, but
- Ability to alert customer when their machine comes back up (aka a "clear" or "ok").
- Ability to suppress alerts on an open alarm. (Yes, I know there is a
  problem here, quit bugging me about it.)
- Ability to disable a monitor.
- Ability for customer to set a maintenance window on a monitor (alert
  suppression for a pre-defined period of time).
- Ability for operator to set a maintenance window on a CN and on the whole
  cloud. This would disable alerts to operator.
  Q:    Disable alerts to customers? How about it adds a "BTW, this is during a
        maint window" ps to each alert? To do this I think we should require an
        explicit operator action to allow that. I.e. a "notifyCustomers=true"
        boolean on the maint window or something. Bletch. Punt for now.
  Q:    If op sets maint on CN-3, for example, there is no way to know to
        disable a "ping" monitor that is running on CN-2 to check a zone
        on CN-3.... unless we add "target_machine" field or something for
        these purposes. Might be reasonable in the UI because the user
        would start with the target machine: "Add ping check to this
        machine. Run it from this other machine."  Do we need this?
- Amon Master API integrated into Cloud API.
- Integration of Monitor management into AdminUI and Portal.
- Upgradable amon system.



# Glossary

- A **monitor** is a the main conceptual object that is configured by operators
  and customers using Amon. It includes the details for what checks to
  run and, when a check trips, who and how to notify ("contacts").
- A **probe** is a single thing to check (the atom of physical monitoring
  done by the Amon agents). E.g. "Check the running state of zone X." "Check
  for 3 occurrences of 'ERROR' in 'foo.log' in zone X within 1 minute." A
  monitor includes one or more probes.
- An **event** is a message sent from an Amon agent up to the Amon master that
  might create or update an alarm.
- An open **alarm** is the state of a failing monitor. An alarm is created
  when a monitor faults (i.e. one of its probes detects a fault). An alarm
  can be closed by user action (via the API or in the Operator or User
  Portals) or via an Amon *clear* event -- the failing state is no longer
  failing, e.g. a halted machine has come back up. An alarm object lives
  until it is closed.
- A **fault** is a single probe failure. An open alarm has one or more
  faults: one for each probe that reported a fault event.
- A **notification** is a message sent for an alarm to one or more contacts
  associated with that monitor. An alarm may result in many notifications
  through its lifetime.
- A **machine** is used to represent any of a software VM, a hardware VM
  (i.e. a zone) or a node (i.e. a physical compute node or server). The
  machine value is a UUID.



# Use Cases

Some Amon use cases to guide its design and to demonstrate how to use
Amon. **Dev Note: Current Amon doesn't support all these use cases yet.**

In the examples below "otto" is an operator account commonly used
in dev work on Amon, "564d70d5-0187-e5d4-468f-7b49a6b014ff" is the headnode
UUID, etc.



## 1. Operator SDC Log Monitor

Probes for watching relevant SDC log files for, say, "ERROR".

    sdc-amon /pub/otto/monitors/sdclogs -X PUT -d- < '{
        "contacts": ["email"]
    }'

    # GZ probes
    sdc-amon /pub/otto/monitors/sdclogs/probes/headnode-ur -X PUT -d- < '{
        "type": "logscan",
        "server": "564d70d5-0187-e5d4-468f-7b49a6b014ff",
        "config": {
            "path": "/var/svc/log/smartdc-agent-ur:default.log",
            "regex": "ERROR",
            "threshold": 1,
            "period": 60
        }
    }'
    # Or perhaps a specialized probe "smf-logscan" type for SMF logs.
    sdc-amon /pub/otto/monitors/sdclogs/probes/headnode-heartbeater -X PUT -d- < '{
        "type": "smf-logscan",
        "server": "564d70d5-0187-e5d4-468f-7b49a6b014ff",
        "config": {
            "fmri": "svc:/smartdc/agent/heartbeater:default",
            "regex": "ERROR",
            "threshold": 1,
            "period": 60
        }
    }'
    ...

    # SDC zones probes
    # Where 'ea3898cd-4ca9-410a-bfa6-0152ba07b1d7' is the ufds0 zone name.
    sdc-amon /pub/otto/monitors/sdclogs/probes/ufds0-ufds-server -X PUT -d- < '{
        "type": "logscan",
        "machine": "ea3898cd-4ca9-410a-bfa6-0152ba07b1d7",
        "config": {
            "path": "/var/log/ufds/server.log",
            "regex": "ERROR",
            "threshold": 1,
            "period": 60
        }
    }'
    ...



## 2. Operator SDC Zones monitor

Probe for SDC zones going up and down. Separate from "SDC Log monitor"
because zone up/down alarms can clear.
See <https://stuff.joyent.us/stuff/trent/screencasts/amon1.mov> for a
screencast demonstrating this use case.

    echo '{
        "contacts": ["email"]
    }' | sdc-amon /pub/SOME-OPERATOR/monitors/sdczones -X PUT -d @-

    # Where 'ea3898cd-4ca9-410a-bfa6-0152ba07b1d7' is the ufds0 zone name.
    echo '{
        "type": "machine-up",
        "machine": "ea3898cd-4ca9-410a-bfa6-0152ba07b1d7"
    }' | sdc-amon /pub/SOME-OPERATOR/monitors/sdczones/probes/ufds0 -X PUT -d @-

    # ... one for each sdc zone (sdc-zapi /vms?tag.smartdc_role=*)
    # See "sdczones.sh" in <https://stuff.joyent.us/stuff/trent/screencasts/amon1-notes.txt>



## 3. Operator SDC Services monitor

Probe for SDC zones' and GZ's "smartdc" services going up/down.

    PUT /my/monitors/services < {
            "contacts": ["email"]
        }
    PUT /my/monitors/services/probes/$machine_alias-$fmri_nickname < {
            "type": "smf",
            "machine": "$machine_uuid",
            "config": {
                "fmri": "$fmri"
            }
        }
    PUT /my/monitors/services/probes/$headnode_hostname-$fmri_nickname < {
            "type": "smf",
            "server": "$compute_node_uuid",
            "config": {
                "fmri": "$fmri"
            }
        }

For example:

    sdc-amon /pub/otto/monitors/sdcservices -X PUT -d- < '{
        "contacts": ["email"]
    }'
    # Where '564d70d5-0187-e5d4-468f-7b49a6b014ff' is my headnode UUID.
    sdc-amon /pub/otto/monitors/sdcservices/probes/headnode-smartlogin -X PUT -d- < '{
        "type": "smf",
        "server": "564d70d5-0187-e5d4-468f-7b49a6b014ff",
        "config": {
            "fmri": "svc:/smartdc/agent/smartlogin:default"
        }
    }'
    ...
    # Where 'ea3898cd-4ca9-410a-bfa6-0152ba07b1d7' is the ufds0 zone name.
    sdc-amon /pub/otto/monitors/sdcservices/probes/ufds0-ufds-capi -X PUT -d- < '{
        "type": "smf",
        "machine": "ea3898cd-4ca9-410a-bfa6-0152ba07b1d7",
        "config": {
            "fmri": "svc:/smartdc/agent/smartlogin:default"
        }
    }'
    ...


## 4. Customer "Machine up" monitor

Probe for each of my machines going up and down.

Portal UX: This monitor is likely often wanted for *all* my zones.
However, don't want it on by default. Should portal's page after
"create new machine" have a big button (or a checkbox) to add this
monitor for this zone. Nice to have would be to offer checkboxes for
all monitors on existing zones: "You have monitor A on (some of) your
other machines. Would you like it on this one too?" Should portal add
a separate monitor? Or add a probe (or probes?) to the same monitor?
Probably another probe to the same monitor. Naming (of probe or
monitor) will be a pain, need to include machine UUID in the name?

Cloud API: You have to add these separately per-machine. That shouldn't
be so bad.

    PUT /my/monitors/machine-up < {
            "contacts": ["email"]
        }
    PUT /my/monitors/machine-up/probes/$machine_uuid < {
            "type": "machine-up",
            "machine": "$machine_uuid"
        }


## 5. Customer "Site up" monitor

Probe to "GET /canary" on the site from some other source location.

    PUT /my/monitors/site < {
            "contacts": ["email"]
        }
    PUT /my/monitors/site/probes/webcheck < {
            "machine": "$machine_uuid",  // <--- this is the machine to run HTTP request from
            "type": "http",
            "config": {
                "url": "http://example.com/canary.html",
                "method": "GET",
                "statusCodes": [200,201,204,401] // number or list of HTTP status numbers to expect
                "regex": "...", // (optional) check for a pattern in returned content
                "interval": 60,  // how often to check (in seconds),
                "period": 300, // alert window
                "threshold": 1 // # of times event must occur within the alert window before alarming
            }
        }


## 6. Operator `mdb -k` goober

Operator wants to run a particular "mdb -k" goober (Bryan's words) to run a
healthcheck on KVM.

    PUT /my/monitors/kvmcheck < {
            "contacts": ["email"]
        }
    PUT /my/monitors/kvmcheck/probes/foo < {
            "type": "mdbkernel",
            "machine": "$machine_uuid",
            "runInGlobal": true,   // must be operator to set this
            "config": {
                // This is essential wide open. That command can presumably
                // do anything.
                "command": ...,
                "regex": "...",   // check for a pattern in returned content?
                // Something to check exit value?
                "interval": 60  // how frequently to check.
            }
        }


## 7. Monitoring a multi-machine webapp

Say we have a set of the following machines for a relatively busy service:

- UUID_MON is our monitor zone
- UUID_DB1 master db zone
- UUID_DB2 slave db zone
- UUID_LB load balancer zone
- UUID_WEBHEAD1 webhead 1 zone
- UUID_WEBHEAD2 webhead 2 zone

We might want monitors like the following. Note that this is using some
probe types that don't exist yet and that aren't a high priority right now.

    # Setup a monitor for the service as a whole. Bad news if this one fails,
    # i.e. that's an argument for severities (TODO: severity).
    sdc-amon /pub/trent/monitors/myservice -X PUT -d '{
      contacts: ["email", "sms"],
      severity: 1
    }'
    sdc-amon /pub/trent/monitors/myservice/probes/ping -X PUT -d '{
      type: "icmp",
      agent: UUID_MON,
      config: {
        "host": "myservice.example.com"
      }
    }'
    sdc-amon /pub/trent/monitors/myservice/probes/http -X PUT -d '{
      type: "http",
      agent: UUID_MON,
      config: {
        "host": "http://myservice.example.com/status"
      }
    }'

    # Setup monitors for each of the other machines: is it up? errors in logs?
    # relevant services up? Slightly lower prio. For example, for WEBHEAD1
    # we might have:
    sdc-amon /pub/trent/monitors/webhead1 -X PUT -d '{
      contacts: ["email", "sms"],
      severity: 2
    }'
    sdc-amon /pub/trent/monitors/webhead1/probes/machineup -X PUT -d '{
      type: "machine-up"
      machine: UUID_WEBHEAD1,
      // This probe type doesn't accept an agent: it runs from the compute
      // node GZ for `machine`.
    }'
    sdc-amon /pub/trent/monitors/webhead1/probes/ping -X PUT -d '{
      type: "icmp",
      agent: UUID_MON,
      config: {
        "host": "1.2.3.4"
      }
    }'
    sdc-amon /pub/trent/monitors/webhead1/probes/http -X PUT -d '{
      type: "http",
      agent: UUID_MON,
      config: {
        "host": "http://1.2.3.4/status",
        "headers": {
          "Host": "myservice.example.com"
        }
      }
    }'
    sdc-amon /pub/trent/monitors/webhead1/probes/myservice -X PUT -d '{
      type: "smf",    // Not yet implemented
      machine: UUID_WEBHEAD1,
      config: {
        "fmri": "myservice"
      }
    }'
    sdc-amon /pub/trent/monitors/webhead1/probes/logerrors -X PUT -d '{
      type: "log-scan",   // or 'smf-log-scan' if/when that is added
      machine: UUID_WEBHEAD1,
      config: {
        "path": "/var/log/myservice.log",
        "regex": "ERROR"
      }
    }'

    # Might want a lower-prio "maintenance" monitor for each machine.
    # For example, WEBHEAD1:
    sdc-amon /pub/trent/monitors/webhead1maint -X PUT -d '{
      contacts: ["email"],
      severity: 3
    }'
    sdc-amon /pub/trent/monitors/webhead1maint/probes/disk -X PUT -d '{
      type: "disk-free",   // Not yet implemented
      machine: UUID_WEBHEAD1,
      config: {
        "path": "/",        // or call this 'mount'?
        "capacity": 0.8   // alarm if disk usage is over 80%
      }
    }'
    sdc-amon /pub/trent/monitors/webhead1maint/probes/ram -X PUT -d '{
      type: "ram-free",   // Not yet implemented
      machine: UUID_WEBHEAD1,
      config: {
        "capacity": 0.9,   // alarm if RAM usage is over 90% 3 times in 5 minutes
        "threshold": 3,
        "period": 300
      }
    }'

    # ... likewise for the other machines.

How would I set a maintenance window to upgrade the DBs?

1. Visit the UUID_DB2 machine page in the portal and set a maint window on
   UUID_DB2 (upgrade slave first).
2. Do upgrades on UUID_DB2 and bring it back up.
3. Check monitoring dashboard, if all is well, close the maint window.
4. Switch over DB master/slave for maint on DB1.
5. Visit the UUID_DB1 machine page in the portal and set a maint window on
   UUID_DB1.
6. Do upgrades on UUID_DB2 and bring it back up.
7. Check monitoring dashboard, if all is well, close the maint window.

Or, if the user doesn't think about setting a maint window (doesn't know
about the feature):

1. Start upgrades on UUID_DB2.
2. Get notification for a db2 monitor alarm (presuming he is on the contact
   list for these monitors), and/or gets a flash message in the portal that
   a new alarm has been raised. Click link to alarm page.
3. Visit alarm page. (This alarm page should include info on other
   recent alarms -- perhaps highlighting those related to the same machine.)
4. "Set maintenance window" for this alarm. Really this translates to a
   maint window on the *monitor* -- which is pretty much, but not exactly,
   the same thing. Also an option when creating the maint window on a monitor
   page is to instead set it on the *machine* ("all monitors for this
   machine").
5. Continue as above...


Notes:
- TODO: ask around. Learn about joyent.com setup. Learn about voxer setup.
  Ask ops about what kinds of monitoring checks they have setup typically.
- TODO: how to monitor percentiles? E.g. prio1 alarm if 90th percentile
  response time is >200ms or something?
